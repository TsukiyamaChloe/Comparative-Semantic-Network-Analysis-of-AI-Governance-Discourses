

--- DOCUMENT: CN_AI+_Action.pdf ---

国务院关于深⼊实施“⼈⼯智能+”⾏动的意见国发〔2025〕11号各省、⾃治区、直辖市⼈民政府，国务院各部委、各直属机构：为深⼊实施“⼈⼯智能+”⾏动，推动⼈⼯智能与经济社会各⾏业各领域⼴泛深度融合，重塑⼈类⽣产⽣活范式，促进⽣产⼒⾰命性跃迁和⽣产关系深层次变⾰，加快形成⼈机协同、跨界融合、共创分享的人工智能经济和人工智能社会新形态，现提出如下意见。⼀、总体要求以习近平新时代中国特⾊社会主义思想为指导，完整准确全⾯贯彻新发展理念，坚持以⼈民为中⼼的发展思想，充分发挥我国数据资源丰富、产业体系完备、应⽤场景⼴阔等优势，强化前瞻谋划、系统布局、分业施策、开放共享、安全可控，以科技、产业、消费、民⽣、治理、全球合作等领域为重点，深⼊实施“⼈⼯智能+”⾏动，涌现⼀批新基础设施、新技术体系、新产业⽣态、新就业岗位等，加快培育发展新质⽣产⼒，使全体⼈民共享⼈⼯人工智能发展成果，更好服务中国式现代化建设。到2027年，率先实现⼈⼯智能与6⼤重点领域⼴泛深度融合，新⼀代智能终端、智能体等应⽤普及率超70%，人工智能经济核⼼产业规模快速增长，⼈⼯智能在公共治理中的作⽤明显增强，⼈⼯智能开放合作体系不断完善。到2030年，我国⼈⼯智能全⾯赋能⾼质量发展，新⼀代智能终端、智能体等应⽤普及率超90%，人工智能经济成为我国经济发展的重要增长极，推动技术普惠和成果共享。到2035年，我国全⾯步⼊人工智能经济和人工智能社会发展新阶段，为基本实现社会主义现代化提供有⼒⽀撑。⼆、加快实施重点⾏动（⼀）“⼈⼯智能+”科学技术1.加速科学发现进程。加快探索⼈⼯智能驱动的新型科研范式，加速“从0到1”重⼤科学发现进程。加快科学⼤模型建设应⽤，推动基础科研平台和重⼤科技基础设施智能化升级，打造开放共享的⾼质量科学数据集，提升跨模态复杂科学数据处理⽔平。强化⼈⼯智能跨学科牵引带动作⽤，推动多学科融合发展。2.驱动技术研发模式创新和效能提升。推动⼈⼯智能驱动的技术研发、⼯程实现、产品落地⼀体化协同发展，加速“从1到N”技术落地和迭代突破，促进创新成果⾼效转化。⽀持智能化研发⼯具和平台推⼴应⽤，加强⼈⼯智能与⽣物制造、量⼦科技、第六代移动通信（6G）等领域技术协同创新，以新的科研成果⽀撑场景应⽤落地，以新的应⽤需求牵引科技创新突破。3.创新哲学社会科学研究⽅法。推动哲学社会科学研究⽅法向⼈机协同模式转变，探索建⽴适应⼈⼯智能时代的新型哲学社会科学研究组织形式，拓展研究视野和观察视域。深⼊研究⼈⼯智能对⼈类认知判断、伦理规范等⽅⾯的深层次影响和作⽤机理，探索形成智能向善理论体系，促进⼈⼯智能更好造福⼈类。（⼆）“⼈⼯智能+”产业发展1.培育智能原⽣新模式新业态。⿎励有条件的企业将⼈⼯智能融⼊战略规划、组织架构、业务流程等，推动产工业全要素智能化发展，助⼒传统产业改造升级，开辟战略性新兴产业和未来产业发展新赛道。⼤⼒发展智能原⽣技术、产品和服务体系，加快培育⼀批底层架构和运⾏逻辑基于⼈⼯智能的智能原⽣企业，探索全新商业模式，催⽣智能原⽣新业态。2.推进⼯工业全要素智能化发展。推动⼯工业全要素智能联动，加快⼈⼯智能在设计、中试、⽣产、服务、运营全环节落地应⽤。着⼒提升全员⼈⼯智能素养与技能，推动各⾏业形成更多可复⽤的专家知识。加快⼯业软件创新突破，⼤⼒发展智能制造装备。推进⼯业供应链智能协同，加强⾃适应供需匹配。推⼴⼈⼯智能驱动的⽣产⼯艺优化⽅法。深化⼈⼯智能与⼯业互联⽹融合应⽤，增强⼯业系统的智能感知与决策执⾏能⼒。3.加快农业数智化转型升级。加快⼈⼯智能驱动的育种体系创新，⽀持种植、养殖等农业领域智能应⽤。⼤⼒发展智能农机、农业⽆⼈机、农业机器⼈等智能装备，提⾼农业⽣产和加⼯⼯具的智能感知、决策、控制、作业等能⼒，强化农机农具平台化、智能化管理。加强⼈⼯智能在农业⽣产管理、风险防范等领域应⽤，帮助农民提升⽣产经营能⼒和⽔平。4.创新服务业发展新模式。加快服务业从数字赋能的互联⽹服务向智能驱动的新型服务⽅式演进，拓展经营范围，推动现代服务业向智向新发展。探索⽆⼈服务与⼈⼯服务相结合的新模式。在软件、信息、⾦融、商务、法律、交通、物流、商贸等领域，推动新⼀代智能终端、智能体等⼴泛应⽤。（三）“⼈⼯智能+”消费提质1.拓展服务消费新场景。培育覆盖更⼴、内容更丰富的智能服务业态，加快发展提效型、陪伴型等智能原⽣应⽤，⽀持开辟智能助理等服务新⼊⼜。加强智能消费基础设施建设，提升⽂娱、电商、家政、物业、出⾏、养⽼、托育等⽣活服务品质，拓展体验消费、个性消费、认知和情感消费等服务消费新场景。2.培育产品消费新业态。推动智能终端“万物智联”，培育智能产品⽣态，⼤⼒发展智能⽹联汽车、⼈⼯智能⼿机和电脑、智能机器⼈、智能家居、智能穿戴等新⼀代智能终端，打造⼀体化全场景覆盖的智能交互环境。加快⼈⼯智能与元宇宙、低空飞⾏、增材制造、脑机接⼜等技术融合和产品创新，探索智能产品新形态。（四）“⼈⼯智能+”民⽣福祉1.创造更加智能的⼯作⽅式。积极发挥⼈⼯智能在创造新岗位和赋能传统岗位⽅⾯的作⽤，探索⼈机协同的新型组织架构和管理模式，培育发展智能代理等创新型⼯作形态，推动在劳动⼒紧缺、环境⾼危等岗位应⽤。⼤⼒⽀持开展⼈⼯智能技能培训，激发⼈⼯智能创新创业和再就业活⼒。加强⼈⼯智能应⽤就业风险评估，引导创新资源向创造就业潜⼒⼤的⽅向倾斜，减少对就业的冲击。2.推⾏更富成效的学习⽅式。把⼈⼯智能融⼊教育教学全要素、全过程，创新智能学伴、智能教师等⼈机协同教育教学新模式，推动育⼈从知识传授为重向能⼒提升为本转变，加快实现⼤规模因材施教，提⾼教育质量，促进教育公平。构建智能化情景交互学习模式，推动开展⽅式更灵活、资源更丰富的⾃主学习。⿎励和⽀持全民积极学习⼈⼯智能新知识、新技术。3.打造更有品质的美好⽣活。探索推⼴⼈⼈可享的⾼⽔平居民健康助⼿，有序推动⼈⼯智能在辅助诊疗、健康管理、医保服务等场景的应⽤，⼤幅提⾼基层医疗健康服务能⼒和效率。推动⼈⼯智能在繁荣⽂化⽣产、增强⽂化传播、促进⽂化交流中展现更⼤作为，利⽤⼈⼯智能辅助创作更多具有中华⽂化元素和标识的⽂化内容，壮⼤⽂化产业。充分发挥⼈⼯智能对织密⼈际关系、精神慰藉陪伴、养⽼托育助残、推进全民健⾝等⽅⾯的重要作⽤，拓展⼈⼯智能在“好房⼦”全⽣命周期的应⽤，积极构建更有温度的人工智能社会。（五）“⼈⼯智能+”治理能⼒1.开创社会治理⼈机共⽣新图景。有序推动市政基础设施智能化改造升级，探索⾯向新⼀代智能终端发展的城市规划、建设与治理，提升城市运⾏智能化⽔平。加快⼈⼯智能产品和服务向乡村延伸，推动城乡智能普惠。深⼊开展⼈⼯人工智能社会实验。安全稳妥有序推进⼈⼯智能在政务领域应⽤，打造精准识别需求、主动规划服务、全程智能办理的政务服务新模式。加快⼈⼯智能在各类公共资源招标投标活动中的应⽤，提升智能交易服务和监管⽔平。2.打造安全治理多元共治新格局。推动构建⾯向⾃然⼈、数字⼈、智能机器⼈等多元⼀体的公共安全治理体系，加强⼈⼯智能在安全⽣产监管、防灾减灾救灾、公共安全预警、社会治安管理等⽅⾯的应⽤，提升监测预警、监管执法、指挥决策、现场救援、社会动员等⼯作⽔平，增强应⽤⼈⼯智能维护和塑造国家安全的能⼒。加快推动⼈⼯智能赋能⽹络空间治理，强化信息精准识别、态势主动研判、风险实时处置等能⼒。3.共绘美丽中国⽣态治理新画卷。提⾼空天地海⼀体化动态感知和国⼟空间智慧规划⽔平，强化资源要素优化配置。围绕⼤⽓、⽔、海洋、⼟壤、⽣物等多要素⽣态环境系统和全国碳市场建设等，提升⼈⼯智能驱动的监测预测、模拟推演、问题处置等能⼒，推动构建智能协同的精准治理模式。（六）“⼈⼯智能+”全球合作1.推动⼈⼯智能普惠共享。把⼈⼯智能作为造福⼈类的国际公共产品，打造平权、互信、多元、共赢的⼈⼯智能能⼒建设开放⽣态。深化⼈⼯智能领域⾼⽔水平开放，推动⼈⼯智能技术开源可及，强化算⼒、数据、⼈才等领域国际合作，帮助全球南⽅国家加强⼈⼯智能能⼒建设，助⼒各国平等参与智能化发展进程，弥合全球智能鸿沟。2.共建⼈⼯智能全球治理体系。⽀持联合国在⼈⼯智能全球治理中发挥主渠道作⽤，探索形成各国⼴泛参与的治理框架，共同应对全球性挑战。深化与国际组织、专业机构等交流合作，加强治理规则、技术标准等对接协调。共同研判、积极应对⼈⼯智能应⽤风险，确保⼈⼯人工智能发展安全、可靠、可控。三、强化基础⽀撑能⼒（七）提升模型基础能⼒。加强⼈⼯智能基础理论研究，⽀持多路径技术探索和模型基础架构创新。加快研究更加⾼效的模型训练和推理⽅法，积极推动理论创新、技术创新、⼯程创新协同发展。探索模型应⽤新形态，提升复杂任务处理能⼒，优化交互体验。建⽴健全模型能⼒评估体系，促进模型能⼒有效迭代提升。（⼋）加强数据供给创新。以应⽤为导向，持续加强⼈⼯智能⾼质量数据集建设。完善适配⼈⼯人工智能发展的数据产权和版权制度，推动公共财政资助项⽬形成的版权内容依法合规开放。⿎励探索基于价值贡献度的数据成本补偿、收益分成等⽅式，加强数据供给激励。⽀持发展数据标注、数据合成等技术，培育壮⼤数据处理和数据服务产业。（九）强化智能算⼒统筹。⽀持⼈⼯智能芯⽚攻坚创新与使能软件⽣态培育，加快超⼤规模智算集群技术突破和⼯程落地。优化国家智算资源布局，完善全国⼀体化算⼒⽹，充分发挥“东数西算”国家枢纽作⽤，加⼤数、算、电、⽹等资源协同。加强智能算⼒互联互通和供需匹配，创新智能算⼒基础设施运营模式，⿎励发展标准化、可扩展的算⼒云服务，推动智能算⼒供给普惠易⽤、经济⾼效、绿⾊安全。（⼗）优化应⽤发展环境。布局建设⼀批国家⼈⼯智能应⽤中试基地，搭建⾏业应⽤共性平台。推动软件信息服务企业智能化转型，重构产品形态和服务模式。培育⼈⼯智能应⽤服务商，发展“模型即服务”、“智能体即服务”等，打造⼈⼯智能应⽤服务链。健全⼈⼯智能应⽤场景建设指引、开放度评价与激励政策，完善应⽤试错容错管理制度。加强知识产权保护、转化与协同应⽤。加快重点领域⼈⼯智能标准研制，推进跨⾏业、跨领域、国际化标准联动。（⼗⼀）促进开源⽣态繁荣。⽀持⼈⼯智能开源社区建设，促进模型、⼯具、数据集等汇聚开放，培育优质开源项⽬。建⽴健全⼈⼯智能开源贡献评价和激励机制，⿎励⾼校将开源贡献纳⼊学⽣学分认证和教师成果认定。⽀持企业、⾼校、科研机构等探索普惠⾼效的开源应⽤新模式。加快构建⾯向全球开放的开源技术体系和社区⽣态，发展具有国际影响⼒的开源项⽬和开发⼯具等。（⼗⼆）加强⼈才队伍建设。推进⼈⼯智能全学段教育和全社会通识教育，完善学科专业布局，加⼤⾼层次⼈才培养⼒度，超常规构建领军⼈才培养新模式，强化师资⼒量建设，推进产教融合、跨学科培养和国际合作。完善符合⼈⼯智能⼈才职业属性和岗位特点的多元化评价体系，更好发挥领军⼈才作⽤，给予青年⼈才更⼤施展空间，⿎励积极探索⼈⼯智能“⽆⼈区”。⽀持企业规范⽤好股权、期权等中长期激励⽅式引才留才⽤才。（⼗三）强化政策法规保障。健全国有资本投资⼈⼯智能领域考核评价和风险监管等制度。加⼤⼈⼯智能领域⾦融和财政⽀持⼒度，发展壮⼤长期资本、耐⼼资本、战略资本，完善风险分担和投资退出机制，充分发挥财政资⾦、政府采购等政策作⽤。完善⼈⼯智能法律法规、伦理准则等，推进⼈⼯智能健康发展相关⽴法⼯作。优化⼈⼯智能相关安全评估和备案管理制度。（⼗四）提升安全能⼒⽔平。推动模型算法、数据资源、基础设施、应⽤系统等安全能⼒建设，防范模型的⿊箱、幻觉、算法歧视等带来的风险，加强前瞻评估和监测处置，推动⼈⼯智能应⽤合规、透明、可信赖。建⽴健全⼈⼯智能技术监测、风险预警、应急响应体系，强化政府引导、⾏业⾃律，坚持包容审慎、分类分级，加快形成动态敏捷、多元协同的⼈⼯智能治理格局。四、组织实施坚持把党的领导贯彻到“⼈⼯智能+”⾏动全过程。国家发展改⾰委要加强统筹协调，推动形成⼯作合⼒。各地区各部门要紧密结合实际，因地制宜抓好贯彻落实，确保落地见效。要强化⽰范引领，适时总结推⼴经验做法。要加强宣传引导，⼴泛凝聚社会共识，营造全社会共同参与的良好氛围。国务院2025年8⽉21⽇

--- DOCUMENT: CN_Content_Labeling.pdf ---

人工智能生成合成内容标识办法第一条为了促进人工智能健康发展，规范人工智能生成合成内容标识，保护公民、法人和其他组织合法权益，维护社会公共利益，根据《中华人民共和国网络安全法》、《互联网信息服务算法推荐管理规定》、《互联网信息服务深度合成管理规定》、《生成式人工智能服务管理暂行办法》等法律、行政法规和部门规章，制定本办法。第二条符合《互联网信息服务算法推荐管理规定》、《互联网信息服务深度合成管理规定》、《生成式人工智能服务管理暂行办法》规定情形的网络信息服务提供者（以下简称“服务提供者”）开展人工智能生成合成内容标识活动，适用本办法。第三条人工智能生成合成内容是指利用人工智能技术生成、合成的文本、图片、音频、视频、虚拟场景等信息。人工智能生成合成内容标识包括显式标识和隐式标识。显式标识是指在生成合成内容或者交互场景界面中添加的，以文字、声音、图形等方式呈现并可以被用户明显感知到的标识。隐式标识是指采取技术措施在生成合成内容文件数据中添加的，不易被用户明显感知到的标识。第四条服务提供者提供的生成合成服务属于《互联网信息服务深度合成管理规定》第十七条第一款情形的，应当按照下列要求对生成合成内容添加显式标识：（一）在文本的起始、末尾或者中间适当位置添加文字提示或者通用符号提示等标识，或者在交互场景界面、文字周边添加显著的提示标识；（二）在音频的起始、末尾或者中间适当位置添加语音提示或者音频节奏提示等标识，或者在交互场景界面中添加显著的提示标识；（三）在图片的适当位置添加显著的提示标识；（四）在视频起始画面和视频播放周边的适当位置添加显著的提示标识，可以在视频末尾和中间适当位置添加显著的提示标识；（五）呈现虚拟场景时，在起始画面的适当位置添加显著的提示标识，可以在虚拟场景持续服务过程中的适当位置添加显著的提示标识；（六）其他生成合成服务场景根据自身应用特点添加显著的提示标识。服务提供者提供生成合成内容下载、复制、导出等功能时，应当确保文件中含有满足要求的显式标识。第五条服务提供者应当按照《互联网信息服务深度合成管理规定》第十六条的规定，在生成合成内容的文件元数据中添加隐式标识，隐式标识包含生成合成内容属性信息、服务提供者名称或者编码、内容编号等制作要素信息。鼓励服务提供者在生成合成内容中添加数字水印等形式的隐式标识。文件元数据是指按照特定编码格式嵌入到文件头部的描述性信息，用于记录文件来源、属性、用途等信息内容。第六条提供网络信息内容传播服务的服务提供者应当采取下列措施，规范生成合成内容传播活动：（一）核验文件元数据中是否含有隐式标识，文件元数据明确标明为生成合成内容的，采取适当方式在发布内容周边添加显著的提示标识，明确提醒公众该内容属于生成合成内容；（二）文件元数据中未核验到隐式标识，但用户声明为生成合成内容的，采取适当方式在发布内容周边添加显著的提示标识，提醒公众该内容可能为生成合成内容；（三）文件元数据中未核验到隐式标识，用户也未声明为生成合成内容，但提供网络信息内容传播服务的服务提供者检测到显式标识或者其他生成合成痕迹的，识别为疑似生成合成内容，采取适当方式在发布内容周边添加显著的提示标识，提醒公众该内容疑似生成合成内容；（四）提供必要的标识功能，并提醒用户主动声明发布内容中是否包含生成合成内容。有前款第一项至第三项情形的，应当在文件元数据中添加生成合成内容属性信息、传播平台名称或者编码、内容编号等传播要素信息。第七条互联网应用程序分发平台在应用程序上架或者上线审核时，应当要求互联网应用程序服务提供者说明是否提供人工智能生成合成服务。互联网应用程序服务提供者提供人工智能生成合成服务的，互联网应用程序分发平台应当核验其生成合成内容标识相关材料。第八条服务提供者应当在用户服务协议中明确说明生成合成内容标识的方法、样式等规范内容，并提示用户仔细阅读并理解相关的标识管理要求。第九条用户申请服务提供者提供没有添加显式标识的生成合成内容的，服务提供者可以在通过用户协议明确用户的标识义务和使用责任后，提供不含显式标识的生成合成内容，并依法留存提供对象信息等相关日志不少于六个月。第十条用户使用网络信息内容传播服务发布生成合成内容的，应当主动声明并使用服务提供者提供的标识功能进行标识。任何组织和个人不得恶意删除、篡改、伪造、隐匿本办法规定的生成合成内容标识，不得为他人实施上述恶意行为提供工具或者服务，不得通过不正当标识手段损害他人合法权益。第十一条服务提供者开展标识活动的，还应当符合相关法律、行政法规、部门规章和强制性国家标准的要求。第十二条服务提供者在履行算法备案、安全评估等手续时，应当按照本办法提供生成合成内容标识相关材料，并加强标识信息共享，为防范打击相关违法犯罪活动提供支持和帮助。第十三条违反本办法规定的，由网信、电信、公安和广播电视等有关主管部门依据职责，按照有关法律、行政法规、部门规章的规定予以处理。第十四条本办法自2025年9月1日起施行。

--- DOCUMENT: CN_Safety_Framework_2.0.pdf ---

前言⼈⼯智能是⼈类发展新领域，深刻改变⼈类⽣产⽣活⽅式，给世界带来前所未有发展机遇，也带来前所未遇⻛险挑战。落实《全球⼈⼯智能治理倡议》，遵循“以⼈为本、智能向善”的发展⽅向，为推动各国政府、⾏业企业、机构组织、社会公众等各⽅以及国际社会，就⼈⼯智能安全治理达成共识、协调⼀致，有效防范应对⼈⼯智能安全⻛险，我们于2024年9⽉制定发布了《⼈⼯智能安全治理框架》1.0版。1.0版发布以来，⼈⼯智能技术和应⽤持续快速发展，个别领域取得超预期突破。例如，⾼性能推理模型涌现，极⼤提⾼了对数学、物理、代码等复杂问题的求解能⼒；⾼效能轻量级模型的开源，显著降低了部署应⽤的⻔槛，⼈⼯智能应⽤迅速向各⾏业领域渗透普及；⼤模型应⽤形态从机器问答向嵌⼊业务流程的智能体演进，加速与业务系统融合；具⾝智能、脑机接⼝技术⽇新⽉异，正在打通连接数字智能和物理世界的“最后⼀公⾥”，⼈机融合的智能时代已不再遥不可及。与此同时，⼈⼯智能安全⻛险的表现形式、影响程度、认识感知亦同步快速演进变化。为应对⼈⼯智能快速发展的新⻛险新挑战，安全有效地释放应⽤需求，促进⼈⼯智能技术和产业发展，在国家互联⽹信息办公室的指导下，全国⽹络安全标准化技术委员会组织国家计算机⽹络应急技术处理协调中⼼等专业机构、科研院所、⾏业企业，持续跟踪⻛险变化，梳理调整⻛险分类，研究探索⻛险分级⽅法，动态调整更新防范治理措施，制定《⼈⼯智能安全治理框架》2.0版，推动增进⼈⼯智能安全治理共识，促进协同共治、普惠共享。1.⼈⼯智能安全治理原则秉持共同、综合、合作、可持续的安全观，坚持发展和安全并重，以促进⼈⼯智能创新发展为第⼀要务，以有效防范化解⼈⼯智能安全⻛险为出发点和落脚点，构建技术与管理相结合、监管与治理相衔接、国内与国际相协同、社会各⽅积极参与且有效互动的治理机制，压实相关主体安全责任，打造全过程全要素治理链条，培育安全、可靠、公平、透明的⼈⼯智能技术研发和应⽤⽣态，积极研究应对⼈⼯智能灾难性⻛险的共识性准则，推动⼈⼯智能健康发展和规范应⽤，切实维护国家主权、安全和发展利益，保障公⺠、法⼈和其他组织的合法权益，确保⼈⼯智能技术造福于⼈类。1.1包容审慎、确保安全。⿎励发展创新，对⼈⼯智能研发及应⽤采取包容态度，通过在安全可控环境下试点等⽅式，为新技术新应⽤发展提供容错纠错空间。严守安全底线，对危害国家安全、社会公共利益、公众合法权益的⻛险及时采取措施。1.2⻛险导向、敏捷治理。密切跟踪⼈⼯智能研发及应⽤趋势，从技术⾃⾝、技术应⽤、衍⽣社会影响等⽅⾯分析梳理安全⻛险；探索从应⽤场景、智能化⽔平、应⽤规模等维度进⾏⻛险分级，进⽽采取相适应的应对措施；持续优化治理机制和⽅式，对确需政府监管事项及时予以响应。1.3技管结合、协同应对。⾯向⼈⼯智能研发应⽤全过程，以及模型开源业态新挑战，综合运⽤技术、管理措施，防范应对不同类型⻛险。围绕⼈⼯智能研发应⽤⽣态链，明确模型算法研发者、服务提供者、系统使⽤者等主体的安全责任，有机发挥政府监管、⾏业⾃律、社会监督等治理机制作⽤。1.4开放合作、共治共享。在全球范围推动⼈⼯智能安全治理国际合作，共享最佳实践，提倡建⽴开放性国际交流合作平台，通过跨学科、跨领域、跨地区、跨国界的对话和合作，推动形成具有⼴泛共识的全球⼈⼯智能治理体系。1.5可信应⽤、防范失控。推动形成涵盖技术防护、价值对⻬、协同治理等多层⾯的可信⼈⼯智能基本准则，确保技术演进安全、可靠、可控，严防威胁⼈类⽣存发展的失控⻛险，确保⼈⼯智能始终处于⼈类控制之下。2.⼈⼯智能安全治理框架构成基于⻛险管理理念，本框架针对不同类型的⼈⼯智能安全⻛险，从技术、管理两⽅⾯提出防范应对措施。2.1安全⻛险分类。通过分析⼈⼯智能技术特性，以及在不同⾏业领域应⽤场景，梳理⼈⼯智能技术本⾝，及其在应⽤过程中⾯临的各种安全⻛险隐患。在1.0版基础上，调整更新⻛险类型，并探索性提出分级应对原则。2.2技术应对措施。针对模型算法、训练数据、算⼒设施、产品服务、应⽤场景，提出通过安全软件开发、数据质量提升、安全建设运维、测评监测加固等技术⼿段，提升⼈⼯智能技术及应⽤安全性的措施。2.3综合治理措施。提出技术研发机构、服务提供者、⽤⼾、政府部⻔、社会组织等各⽅发现、防范、应对⼈⼯智能安全⻛险的措施⼿段，以及深化⼈⼯智能安全治理国际交流合作等建议，推动相关各⽅协同共治。2.4研发与应⽤的安全指引。提出模型算法研发、建设部署、运⾏管理，以及访问使⽤的引导性安全规范。此外，针对潜在的技术失控⻛险，提出可信⼈⼯智能基本准则，引导国际社会共识。3.⼈⼯智能安全⻛险分类⼈⼯智能既存在模型算法缺陷、数据语料质量问题等技术内⽣安全⻛险，也存在技术整合交付应⽤时的⽹络系统、信息内容等⽅⾯应⽤安全⻛险，还⾯临技术误⽤、滥⽤、恶⽤冲击现实社会环境、⼈类认知伦理的衍⽣安全⻛险，甚⾄是灾难性⻛险。3.1⼈⼯智能技术内⽣安全⻛险3.1.1模型算法安全⻛险（a）可解释性不⾜。以深度学习为代表的⼈⼯智能算法运⾏逻辑复杂，推理过程不透明，可能导致决策输出难以预测和归因，异常、故障、错误难以快速修正和溯源追责。（b）偏⻅、歧视。模型算法研发设计及训练过程中，偏⻅、歧视等问题被有意、⽆意引⼊，或因训练数据质量、多样性问题，导致算法设计⽬的、决策判断、输出结果存在偏⻅或歧视，甚⾄输出存在⺠族、信仰、国别、地域、性别等歧视性内容。（c）鲁棒性不强。由于深度神经⽹络存在⾮线性、⼤规模等特点，⼈⼯智能易受复杂多变运⾏环境或恶意⼲扰、诱导的影响，可能带来性能下降、决策错误等鲁棒性问题。（d）输出决策不可靠。⼈⼯智能利⽤有限数据集拟合复杂现实世界，⾃主感知、认识、理解、交互的理论基础、技术能⼒还有待突破，基于有限样本的决策判断、输出结果存在“幻觉”,即看似合理实则不可靠的现象。（e）外部对抗攻击。攻击者利⽤模型算法及其设计实现的缺陷、漏洞，构造对抗攻击样本数据，窃取、篡改模型参数、结构、功能等，⼲预模型推理过程进⽽影响决策判断、输出结果及运⾏稳定性，甚⾄恶意利⽤或消耗模型资源。（f）模型缺陷扩散。依托基础模型进⾏⼆次开发或微调、建设部署⼈⼯智能应⽤，将导致基础模型缺陷向下游模型、应⽤传导。基础模型的开源，加剧模型缺陷扩散速度、影响范围和修补难度，为不法分⼦训练“作恶模型”提供便利。3.1.2数据安全⻛险（a）违规收集使⽤数据。⼈⼯智能训练数据的获取，以及服务、交互过程中，存在未经同意收集、不当使⽤数据和个⼈信息的安全⻛险。（b）训练数据内容不当。训练数据包含虚假、偏⻅、侵犯知识产权等违法有害内容，还⾯临攻击者篡改、注⼊错误、误导数据的“投毒”⻛险，影响模型价值观对⻬，“污染”模型概率分布，造成决策输出准确性、可信度下降，甚⾄输出违法有害信息。（c）训练数据标注不规范。训练数据标注过程中，存在标注规则不完备、标注⼈员能⼒不⾜、标注错误等问题，影响模型算法准确度、可靠性、有效性，还可能导致训练偏差、偏⻅歧视放⼤、泛化能⼒不⾜或决策判断输出错误。（d）数据和个⼈信息泄露。⼈⼯智能训练数据蕴含的知识、敏感信息暗藏于模型参数之中，因模型安全防护机制不健全、敏感信息未“遗忘”、诱导交互和恶意攻击，可能导致数据和个⼈信息泄露。3.2⼈⼯智能技术应⽤安全⻛险3.2.1⽹络系统安全⻛险（a）组件和算⼒安全。⼈⼯智能依赖的开发框架、计算框架、执⾏平台、算⼒设施等，存在缺陷、漏洞、后⻔、可靠性等⻛险。同时，⾯临算⼒资源恶意消耗，以及安全问题在多源、异构、泛在算⼒资源间跨边界传递的⻛险。（b）⽹络暴露⾯扩⼤。模型本地化部署涉及⽹络拓扑和系统策略、权限、端⼝、资源的调整配置，易形成新的⽹络攻击⼊⼝和路径。智能体需调⽤终端系统⽂件、权限、接⼝、⼯具，以实现复杂任务⾃主规划⾃动执⾏，加剧⽂件泄露、权限滥⽤等安全⻛险。（c）供应链安全。⼈⼯智能产业链呈现⾼度全球化分⼯协作格局。但个别国家利⽤技术垄断和出⼝管制等单边强制措施制造发展壁垒，恶意阻断全球⼈⼯智能供应链，带来突出的芯⽚、软件、⼯具断供⻛险。（d）⽹络攻击滥⽤。⼈⼯智能可被⽤于降低⽹络攻击⻔槛，提⾼攻击效率甚⾄实施⾃动化攻击，增⼤防护难度。特别是可⽤于⽣成图⽚、⾳频、视频等⾼仿真内容，绕过⼈脸识别、语⾳识别等⾝份认证机制，导致认证鉴权失效。3.2.2信息内容安全⻛险（a）输出违法有害信息。模型⾃⾝安全能⼒不⾜，叠加应⽤防护机制不强、⽤⼾恶意诱导等因素，导致⽣成输出欺诈、暴⼒、⾊情、极端主义等违法有害信息，威胁社会稳定、公共安全和意识形态安全。（b）混淆事实、误导⽤⼾。⼈⼯智能输出内容未经标识，特别是“深伪”技术的应⽤，导致⽤⼾难以识别⽣成内容来源及交互对象是否为⼈⼯智能系统，难以鉴别⽣成内容的真实性，影响⽤⼾判断，还可被⽤于制作传播虚假信息误导公众、⾮法牟利。（c）污染⽹络内容⽣态。模型输出的低质不良信息，经⽹络扩散传播、模型循环引⽤，造成⽹络内容质量的整体下降，甚⾄特定领域、话题的内容污染。3.2.3现实安全⻛险（a）经济社会运⾏安全的新挑战。⼈⼯智能应⽤于能源、电信、⾦融、交通等关键信息基础设施⾏业领域，模型算法的幻觉输出、错误决策，以及不当使⽤、外部攻击等，可能引发系统性能下降、服务中断、操作执⾏失控等问题，加剧关键信息基础设施安全稳定运⾏⻛险。（b）被违法犯罪活动利⽤“作恶”。⼈⼯智能可被利⽤于涉恐、涉暴、涉赌、涉毒等传统违法犯罪活动，包括传授违法犯罪技巧、隐匿违法犯罪⾏为、制作违法犯罪⼯具等。（c）核⽣化导武器知识、能⼒失控。⼈⼯智能在训练过程中多使⽤⻔类宽泛、内容丰富的语料数据，其中包含核⽣化导武器相关基础理论知识，辅以检索增强⽣成功能，如不能有效管控，将被极端势⼒、恐怖分⼦利⽤于获取相关知识，以及设计、制造、合成、使⽤核⽣化导武器能⼒，导致现有管控体系失效，加剧世界各地区和平安全威胁。3.2.4认知安全⻛险（a）加剧“信息茧房”效应。⼈⼯智能将显著提升信息服务定制化能⼒，更为准确地收集⽤⼾信息，分析⽤⼾需求、意图、喜好、⾏为习惯，甚⾄特定时段、特定群体的意识思潮，进⽽推送精准定制化信息服务,加剧⽤⼾所关注信息的局限性。（b）助⼒开展认知战。⼈⼯智能被⽤于宣扬恐怖主义、极端主义、有组织犯罪等内容，⼲涉他国内政、社会制度及社会秩序，危害他国主权；通过社交机器⼈在⽹络空间抢占话语权和议程设置权，左右公众价值观和思维认知。3.3人工智能应用衍生安全风险3.3.1社会和环境安全⻛险（a）冲击劳动就业结构。⼈⼯智能带来⽣产⼒、⽣产关系的⼤幅调整，加速重构传统经济结构，资本、技术与数据在经济活动中的地位全⾯提升，⽽劳动⼒要素的价值受到削弱，造成传统劳动⼒需求明显下降。（b）挑战资源供需平衡。⼈⼯人工智能发展中的算⼒设施⽆序建设、轻量模型碎⽚化部署、同质化模型低效重复开发等问题，加速电⼒、⼟地、⽔等能源资源消耗，对资源供需平衡、绿⾊低碳发展带来新的挑战。3.3.2伦理安全⻛险（a）加剧社会偏⻅、扩⼤智能鸿沟。利⽤⼈⼯智能收集分析⼈类⾏为、社会地位、经济状态、个体性格等，对不同⼈群进⾏标识分类、区别对待，带来系统性、结构性的社会歧视与偏⻅。同时，拉⼤不同地区⼈⼯智能鸿沟。（b）冲击教育、抑制创新。学⽣及科研、⼯程技术、⽂学艺术⼯作者将⼈⼯智能⼯具⼴泛应⽤于知识学习、科学研究、创意创作等⼯作，在提升效率的同时，可能产⽣⼯具依赖，⾃主学习、研究、创作能⼒退化，创新潜⼒减弱。（c）加剧科研伦理⻛险。“⼈⼯智能+科研”降低⽣物、基因等⾼伦理⻛险科研领域的进⼊⻔槛，拓宽了普通科研机构、⼈员探索敏感科学问题的边界，个别科研伦理意识不强的机构、⼈员可能开展违背社会伦理、社会禁忌的⾼⻛险研究活动，打开科技“魔盒”。（d）拟⼈化交互的沉迷依赖。基于拟⼈化交互的⼈⼯智能产品，导致⽤⼾对其产⽣情感依赖，进⽽影响⽤⼾⾏为，造成社会伦理⻛险。（e）挑战现⾏社会秩序。⼈⼯人工智能发展及应⽤，带来⽣产⼯具、⽣产关系的⼤幅改变，加速重构传统⾏业模式，颠覆传统的就业观、⽣育观、教育观，挑战传统社会秩序。（f）“⾃我意识”觉醒、脱离⼈类控制。未来，不排除⼈⼯智能出现突发的、超预期的智能化⽔平“跃迁”，⾃主获取外部资源、⾃我复制，产⽣⾃我意识，寻求外部权⼒，带来谋求与⼈类争夺控制权的⻛险。4.技术应对措施针对上述⻛险，模型算法研发者、服务提供者、系统使⽤者等需从训练数据、模型算法、算⼒设施、产品服务、应⽤场景各⽅⾯采取技术措施予以防范。4.1技术内⽣安全⻛险的应对措施4.1.1模型算法安全⻛险应对（a）提升⼈⼯智能可解释性、透明性，为⼈⼯智能系统内部构造、推理逻辑、技术接⼝、输出结果提供明确说明，正确反映⼈⼯智能系统产⽣结果的过程。（b）改进模型架构，扩充训练数据的规模和多样性，引⼊⼈类监督机制，减轻偏⻅歧视，提升模型的泛化能⼒和输出结果可靠性。（c）在设计、研发过程中建⽴并实施安全开发规范，消减模型算法安全缺陷，对模型进⾏对抗性训练，降低模型易受提⽰注⼊攻击的⻛险，提⾼鲁棒性。（d）加强基础模型、开源模型安全缺陷传导评估。4.1.2数据安全⻛险应对（a）在训练数据和⽤⼾交互数据的收集、存储、使⽤、加⼯、传输、提供、公开、删除等各环节，应遵循数据收集使⽤、个⼈信息处理的安全规则，严格落实关于⽤⼾控制权、知情权、选择权等法律法规明确的合法权益。（b）使⽤真实、准确、客观、多样且来源合法的训练数据，对训练数据进⾏严格筛选，过滤虚假、偏⻅、失效、错误数据，确保不包含核⽣化导武器等⾼危领域敏感数据。（c）规范训练数据标注流程，提升标注准确性和可靠性。（d）强化数据安全管理，涉及敏感个⼈信息和重要数据的，应符合数据安全和个⼈信息保护相关法律法规、标准规范。合理推动利⽤合成数据替代个⼈特征数据，避免个⼈信息依赖。（e）加强知识产权保护，在训练数据选择、结果输出等环节防⽌侵犯知识产权。4.2技术应用安全风险的应对措施4.2.1⽹络系统安全⻛险应对（a）对⼈⼯智能技术和产品的原理、能⼒、适⽤场景、安全⻛险进⾏必要披露，不断提⾼⼈⼯智能系统透明性。（b）对聚合多个⼈⼯智能模型或系统的平台，加强权限管理，禁⽤⾮必要服务，完善⼈⼯智能服务接⼝的访问控制策略，提升⻛险识别、检测、防护能⼒，防⽌因平台恶意⾏为或被攻击⼊侵影响承载的⼈⼯智能模型或系统。（c）在⼈⼯智能应⽤部署、维护过程中建⽴并实施安全规范，消减缺陷、漏洞、后⻔，跟踪软硬件产品的漏洞、缺陷信息，定期进⾏安全检测和漏洞扫描，并及时采取修补加固措施，确保系统安全、稳定运⾏。（d）对于⼈⼯智能系统采⽤的芯⽚、软件、⼯具、算⼒和数据资源，⾼度关注供应链安全。（e）完善冗余设计与容灾机制，确保异常或受攻击时，系统仍能正常运⾏。4.2.2信息内容安全⻛险应对（a）建⽴安全防护机制，防⽌模型运⾏过程中被⼲扰、篡改⽽输出不可信结果。（b）建⽴安全护栏，对输⼊输出进⾏动态过滤，防⽌恶意注⼊和违法内容⽣成，避免⼈⼯智能系统违法违规输出敏感个⼈信息和重要数据。（c）对⼈⼯智能⽣成合成内容进⾏标识，实现可识别、可追溯、可信赖。4.2.3现实安全⻛险应对（a）根据应⽤场景设置能⼒边界，裁减⼈⼯智能系统可能被滥⽤的功能，确保智能系统能⼒不超出预设范围。（b）针对算法缺陷、偶发随机性影响决策问题，建⽴决策判断校验、容错及纠偏机制。（c）在引⼊⾼度⾃主操作执⾏能⼒时，同步建⽴“熔断”、“⼀键管控”等措施，实现极端情况下迅速⼲预⽌损。（d）对于智能辅助驾驶、⽆⼈机等依赖对物理世界强感知的⼈⼯智能应⽤场景，在投⼊使⽤前对感知系统进⾏在⼤⾯积遮挡、强电磁⼲扰等极端条件下的测试。（e）提⾼⼈⼯智能系统最终⽤途追溯能⼒，防⽌被⽤于核⽣化导等⼤规模杀伤性武器制造等⾼危场景。4.2.4认知安全⻛险应对（a）通过技术⼿段判别不符合预期、不真实、不准确的输出结果，并依法依规监管。（b）对收集⽤⼾提问信息进⾏关联分析、汇聚挖掘，进⽽判断⽤⼾⾝份、喜好以及个⼈思想倾向的⼈⼯智能系统，应严格防范其滥⽤。（c）加强对⼈⼯智能⽣成合成内容的检测技术研发，提升对认知战⼿段的防范、检测、处置能⼒。4.3应⽤衍⽣安全⻛险的应对措施4.3.1社会和环境安全⻛险应对（a）⽀持不断探索创新资源节约、环境友好的⼈⼯人工智能发展模式，制定⼈⼯智能绿⾊技术标准。（b）推⼴低功耗芯⽚、⾼效算法等绿⾊计算技术和能效优化⽅案，降低能源等资源消耗。4.3.2伦理安全⻛险应对（a）在算法设计、模型训练和优化、提供服务过程中，采取训练数据筛选、价值观对⻬、输出校验等⽅式，有效规避产⽣⺠族、信仰、国别、地域、性别等歧视的⻛险。（b）应⽤于政府部⻔、关键信息基础设施以及直接影响公共安全和公⺠⽣命健康安全等重点领域的⼈⼯智能系统，需具备⾼效精准的应急管控措施。（c）⿎励研发和采⽤具备透明决策逻辑的模型和可解释算法，提升⽤⼾对系统运⾏机制的理解和信任。5.综合治理措施在采取技术应对措施的同时，建⽴完善技术研发机构、服务提供者、⽤⼾、政府部⻔、社会组织等多⽅参与的⼈⼯智能安全⻛险综合治理制度规范。5.1建⽴健全⼈⼯智能安全法律法规。推动⼈⼯智能安全相关⽴法，完善基础设施安全防护、分级分类监管、⼈⼯智能安全测评、最终⽤途管理、重点场景安全应⽤等制度。⿎励地⽅结合产业发展实践，差异化探索创新制度设计。5.2构建⼈⼯智能科技伦理准则。制定有⼴泛共识的⼈⼯智能科技伦理准则、规范和指南，对在⽣命健康、⼈格尊严、劳动就业、⽣态环境、可持续发展等⽅⾯存在突出伦理⻛险的⼈⼯智能科学研究、技术开发等活动，规范有序开展伦理审查。推进⼈⼯智能科技伦理服务体系建设，强化服务供给，加⼤对中⼩微企业的⽀持⼒度。5.3提升研发应⽤全⽣命周期安全能⼒。持续提升算法可靠性、可信度、透明度、容错机制、隐私保护、价值观对⻬等内⽣安全能⼒，利⽤对抗测试等技术评估改进模型鲁棒性，降低模型算法潜在偏⻅，确保价值观、伦理⻛险可控，避免⼈⼯智能系统意外决策产⽣恶意⾏为。5.4强化开源⽣态安全和供应链安全。在培育发展开源创新⽣态的同时，同步提升开源⽣态安全能⼒。⿎励⽀持训练推理框架、软件⼯具、关键组件、评测基准等全⽅位的⼈⼯智能技术开源，进⼀步提⾼开源模型透明度。推动开源模型提供⽅、开源社区共同完善开源规则，强化⾯向模型下载⽤⼾的安全责任、⻛险隐患告知责任与义务，明确开源模型下载使⽤的“禁⽌性”⾏为，防范模型滥⽤或恶意使⽤。持续推进⼈⼯智能芯⽚、框架、软件开放供应链⽣态建设，增强产品服务供应多样性，保障供应链安全稳定。5.5实施应⽤分类及安全⻛险分级管理。根据功能、性能、应⽤场景等，对⼈⼯智能应⽤进⾏分类。在此基础上，探索提出具有共识的安全⻛险分级原则（附件1），从应⽤场景、智能化⽔平、应⽤规模等维度⼊⼿，对安全⻛险进⾏科学评价分级，进⽽采取针对性、差异化安全防范措施。对在关键信息基础设施应⽤的⼈⼯智能系统进⾏登记备案，要求其具备与安全需求相匹配的安全防护能⼒。5.6推⼴⼈⼯智能⽣成合成内容可追溯管理。在全球范围内推⼴基于内容标识的⼈⼯智能⽣成合成内容溯源管理范式，总结梳理已有实践的成功做法经验，按照显式、隐式等标识要求，全⾯覆盖制作源头、传播路径、分发渠道等关键环节，便于浏览⽤⼾识别判断信息来源及真实性。5.7安全有效释放重要⾏业应⽤需求。制定重要⾏业领域⼤模型建设部署基础安全指南，从模型选⽤、模型部署、模型运⾏和模型停⽤等环节，提出安全基线建议。在此基础上，相关⾏业领域结合⾃⾝属性特点，制定能源、电信、⾦融、交通、教育、⼯业等重要⾏业领域的应⽤安全指南，形成清晰的安全应⽤路径，释放⾏业应⽤潜⼒。5.8建设⼈⼯智能安全测评体系。构建模型算法安全测评、应⽤通⽤安全测评、具体场景安全测评相衔接的⼈⼯智能安全测评体系。模型算法测评，聚焦模型鲁棒性、可靠性、准确性、抗⼲扰能⼒、决策逻辑透明度、对抗攻击防御能⼒等内⽣安全能⼒和⻛险。应⽤通⽤测评，针对普遍使⽤的⼈⼯智能应⽤⻛险开展测试分析评估。具体场景安全测评，结合应⽤场景具体情况评估满⾜应⽤需求的能⼒，以及应⽤运⾏和服务过程中的安全⻛险。组织开展⼈⼯智能安全漏洞众测活动，汇集各⽅⼒量发现潜在安全⻛险。5.9共享⼈⼯智能安全⻛险威胁信息。跟踪分析⼈⼯智能技术、产品、服务安全漏洞、缺陷、⻛险威胁、安全事件信息，建设⼈⼯智能漏洞信息库，建⽴覆盖研发者、服务提供者、专业技术机构的⻛险威胁信息共享机制。推进⼈⼯智能安全⻛险威胁信息共享的国际交流合作，探索建⽴相关国际合作机制和技术标准，协同防范应对⼈⼯智能安全⻛险⼤跨域、⼤规模扩散传播。5.10完善数据安全和个⼈信息保护规范。针对⼈⼯智能技术及应⽤特点，明确⼈⼯智能训练、标注、使⽤、输出等各环节的数据安全和个⼈信息保护要求。对涉及个⼈信息的数据实施去标识化等脱敏处理。加强政务、⾦融等重要⾏业领域⼈⼯智能应⽤中的数据安全防护，防范重要数据、核⼼数据泄露⻛险。5.11增进协同应对⼈⼯智能失控⻛险的共识。加强⼈⼯智能最终⽤途管理，对核⽣化导等场景下使⽤⼈⼯智能技术提出相关要求，防⽌⼈⼯智能系统被滥⽤。推⼴涵盖技术、伦理、管理多维度的可信⼈⼯智能基本准则，促进国际社会形成⼴泛共识（附件2）。开发者定期进⾏测试，判断模型是否可能带来潜在技术失控⻛险。5.12加⼤⼈⼯智能安全⼈才培养⼒度。推进⼈⼯智能安全课程体系、培养体系建设，形成从基础教育到⾼等教育的完整培养链条。加强⼈⼯智能安全设计、开发、治理⼈才培养，⽀持培养⼈⼯智能安全前沿基础领域顶尖⼈才，壮⼤⽆⼈驾驶、智慧医疗、类脑智能、脑机接⼝等重点、前沿领域的安全⼈才队伍。5.13提升全社会的⼈⼯智能安全意识。⾯向政府、企业、社会公⽤事业单位加强⼈⼯智能安全规范应⽤的教育培训。结合互动平台、开放课程与社区科普活动，加强⼈⼯智能安全⻛险及防范应对知识的宣传，全⾯提⾼全社会⼈⼯智能安全意识，使政府、⾏业与公众能准确认识⼈⼯智能的技术局限。指导⽀持⽹络安全、⼈⼯智能领域⾏业协会加强⾏业⾃律，制定提出⾼于监管要求、具有引领⽰范作⽤的⾃律要求；建⽴⾯向公众⼈⼯智能安全⻛险隐患举报受理机制，形成有效的社会监督氛围。5.14促进人工智全理国际合作。坚持践⾏多边主义，推动共商共建共享的⼈⼯智能全球治理观。⽀持联合国发挥主渠道作⽤，深⼊参与联合国国际⼈⼯智能科学⼩组和全球⼈⼯智能治理对话机制。推进APEC、G20、上合组织、⾦砖国家等多边机制下的⼈⼯智能治理进程，加强与“⼀带⼀路”国家、“全球南⽅”国家合作，增强发展中国家在⼈⼯智能全球治理中的代表性和发⾔权，推进《⼈⼯智能全球治理⾏动计划》。6.⼈⼯智能研发与应⽤的安全指引6.1⼈⼯智能模型算法研发的安全开发指引6.1.1在算法规则、模型框架设计环节，应考虑提升算法可靠性、公平性、透明度、可解释性、隐私保护、价值观对⻬等内⽣安全能⼒设计。6.1.2评估模型算法潜在偏⻅，加强训练数据内容和质量的抽查检测，设计有效、可靠的对⻬算法，确保价值观⻛险、伦理⻛险等可控。6.1.3确保模型算法训练环境的安全性，包括⽹络安全配置和数据加密措施等。结合安全测试发现的⾼⻛险问题，通过针对性的微调、强化学习等⽅式优化模型，持续提升模型内⽣安全能⼒。6.1.4关注和构建安全的训练数据集，规范数据来源管理，采⽤数据清洗、标注、安全审核等⽅法确保训练数据内容的安全性，确保数据来源清晰、内容合规。6.1.5对训练数据进⾏质量和安全性评估，采取分类模型、⼈⼯抽检等⽅式，过滤训练数据中的错误、违法不良内容。6.1.6规范训练数据标注流程，采⽤交叉标注、结果审计等质量控制⽅法，提升标注准确性和可靠性，降低个体差异和个⼈偏⻅对标注质量的影响。6.1.7重视数据安全和个⼈信息保护，尊重知识产权和版权。建⽴完善的数据安全管理制度，遵循正当合法必要原则收集、使⽤和处理个⼈信息，对涉及个⼈信息的数据实施去标识化等脱敏处理。加强数据安全防护技术能⼒，防范数据泄露、流失、扩散、侵权等⻛险。6.1.8基于开源模型算法进⾏⼆次开发的研发者，在尊重研发者智⼒投⼊的基础上，遵循相应开源协议规范。对所使⽤的开发框架、代码等进⾏安全审计，并关注开源框架安全及漏洞相关问题，识别和修复潜在的安全漏洞。6.1.9定期开展安全评估测试，制定⻛险分类分级测评与优化机制，测试前明确测试⽬标、范围和安全维度，构建多样化的测试数据集，涵盖各种应⽤场景，并制定各类⻛险的针对性模型优化策略。6.1.10做好⼈⼯智能模型及所⽤数据集的版本管理，商⽤版本应可以回退到以前的版本。6.1.11制定明确的测试规则和⽅法，包括⼈⼯测试、⾃动测试、混合测试等，利⽤沙箱仿真等技术对模型进⾏充分测试和验证。⽤于商业化⽤途的研发者，应形成详细的测试报告，分析安全问题并提出改进⽅案。6.1.12评估⼈⼯智能模型算法对外界⼲扰的容忍程度，以适⽤范围、注意事项或使⽤禁忌的形式告知服务提供者和其他研发者。6.1.13定期披露⼈⼯智能模型算法的审计与异常处置情况。6.1.14积极参与开源社区建设，推动⼈⼯智能安全治理技术创新和实践，为服务提供者和使⽤者提供合规治理解决⽅案或治理⼯具。6.2⼈⼯智能应⽤建设部署的安全指引6.2.1评估⽬标场景应⽤⼈⼯智能技术的必要性及使⽤后的⻓期和潜在影响，结合其应⽤场景重要性、智能化⽔平、应⽤规模等进⾏⻛险分级，参考⻛险等级开展安全评估和定期审计。6.2.2增强供应链安全保障能⼒，建设部署所需模型⽂件、框架⼯具、第三⽅库等，应从相关⼚商官⽅⽹站或其在主流开源社区的官⽅账号下获取，选取成熟稳定的版本，并进⾏完整性校验和安全测试。6.2.3对建设部署所需的软硬件设备、第三⽅⼯具等进⾏安全检测，确保不含未修复且可被利⽤的已知漏洞。建⽴漏洞追溯机制，跟踪相关软硬件安全漏洞、缺陷信息，防范供应链植⼊后⻔。6.2.4在访问控制层⾯，准确安装配置软件、运⾏环境参数、功能模块调⽤策略，禁⽤⾮必要的⽹络端⼝和功能服务，重点检查默认配置、默认⼝令，及时修复安全⻛险。6.2.5在应⽤管理层⾯，对⼈机交互接⼝和API接⼝进⾏⽤⼾⾝份识别及权限控制，最⼩化设置访问权限，根据业务场景限制接⼝调⽤频率，对⼀般⽤⼾禁⽤⾼⻛险操作，对恶意⾏为⽤⼾建⽴暂停服务、阻断访问等管控能⼒。6.2.6全⾯了解应⽤场景的数据安全和隐私保护要求，合理限制对数据的访问权限，防⽌超范围使⽤数据，制定数据备份和恢复计划，并定期对数据处理流程进⾏检查。6.2.7采⽤安全护栏等技术⼿段，识别拦截违法不良内容、提⽰词注⼊攻击等，防范输出内容超出业务范围。6.3⼈⼯智能应⽤运⾏管理的安全指引6.3.1建⽴完善的⼈⼯智能应⽤安全管理和监督机制，明确责任⽅，健全⼈⼯复核机制，保障在关键场景应⽤中⼈⼯智能应⽤决策透明、可控，并提供清晰的决策依据，确保⼈⼯智能应⽤在⼈类授权和控制下运⾏。6.3.2严格管理⼈⼯智能应⽤权限，通过最⼩权限原则等⼿段强化内部安全管理，增强账⼾安全性，在处理敏感数据时使⽤加密技术等保护措施。6.3.3建⽴⼈⼯智能应⽤运⾏监测能⼒和安全事件应急预案，设置其关键指标的安全预警阈值，能够及时发现安全事件，并具备切换到⼈⼯或传统系统等的能⼒。定期开展应急演练，并根据⾏业安全事件、重要舆情及监管变化，及时优化应急策略，应对不断变化的安全⻛险。6.3.4在⼈⼯智能⽣成内容内添加显式或隐式标识，做好⽣成合成内容提⽰和溯源管理。在政务信息公开、司法取证等场景部署深度伪造检测⼯具，对疑似⼤模型⽣成的信息实施来源核验与交叉验证。6.3.5制定信息内容交互⾏为规范、安全运营机制、投诉反馈机制、技术防护能⼒等，防范⼈⼯智能应⽤被不当或恶意利⽤⽣成、发布、传播虚假有害信息⻛险。6.3.6记录⼈⼯智能应⽤运⾏⽇志，包括系统⾏为、⽤⼾⾏为等，⽇志留存时间不少于6个⽉，并定期对⽇志记录进⾏审计。6.3.7建⽴健全实时⻛险监控管理机制，持续跟踪运⾏中安全⻛险。6.3.8提升应⽤的透明度、公平性，公开⼈⼯智能应⽤的能⼒、局限性、适⽤⼈群、场景。6.3.9应向使⽤者说明⼈⼯智能应⽤的⽬标实现度和偏离度，在⼈⼯智能决策有重⼤影响时，做好解释说明。6.3.10维护使⽤者的知情权、选择权、监督权等合法权益，在合同或服务协议中，以使⽤者易于理解的⽅式，告知⼈⼯智能应⽤的适⽤范围、注意事项、使⽤禁忌，⽀持使⽤者知情选择、审慎使⽤。6.3.11在告知同意、服务协议等⽂件中，⽀持使⽤者⾏使⼈类监督和控制权利。6.3.12明确具体应⽤中的数据归属及算法缺陷的责任主体，确保责任链条可追溯。6.3.13落实数据安全管理责任，评估⼈⼯智能应⽤中存在的数据泄露、个⼈隐私泄露、违规收集使⽤个⼈信息等⻛险，建⽴数据全⽣命周期安全管理机制，提升数据防泄漏、防窃取保障能⼒。6.3.14评估⼈⼯智能应⽤在⾯临故障、攻击等异常条件下抵御或克服不利条件的能⼒，防范出现意外结果和⾏为错误，确保最低限度有效功能。6.3.15加强从业⼈员安全意识和安全能⼒培训，提⾼⼈⼯智能安全⻛险防范意识。6.3.16在合同或服务协议中明确，⼀旦发现不符合使⽤意图和说明限制的误⽤、滥⽤，提供者有权采取纠正措施或提前终⽌服务。6.3.17⾯向未成年⼈、⽼年⼈及特殊群体提供⼈⼯智能服务，应在产品功能设计、服务模式等环节，充分考虑可⽤性和安全性。6.4⼈⼯智能应⽤访问使⽤的安全指引6.4.1提⾼对⼈⼯智能应⽤安全⻛险的认识，选择信誉良好的⼈⼯智能应⽤。6.4.2在使⽤前仔细阅读产品合同或服务协议，了解应⽤的功能、限制和隐私政策，准确认知⼈⼯智能应⽤做出判断决策的局限性，合理设定使⽤预期。6.4.3提⾼个⼈信息保护意识，避免在不必要的情况下输⼊敏感信息。6.4.4了解⼈⼯智能应⽤的数据处理⽅式，避免使⽤不符合隐私保护原则的产品。6.4.5在使⽤⼈⼯智能应⽤时，应关注⽹络安全⻛险，避免⼈⼯智能应⽤成为⽹络攻击的⽬标。6.4.6注意⼈⼯智能应⽤对⼉童和⻘少年的影响，预防沉迷及过度使⽤。安全风险与技术应对措施、综合治理措施映射表人人机工工智智智能能能应应应用用用衍衍衍生生生安安安全全全风风风险险险提升全社会的人工智能安全意识附件1⼈⼯智能安全⻛险的分级原则⼈⼯智能安全⻛险的评价涉及诸多因素。可从应⽤场景重要性、智能化⽔平、应⽤规模等维度，对⼈⼯智能安全⻛险进⾏评价分级，进⽽针对性采取安全防范措施。⼀、主要分级要素1.应⽤场景应⽤场景反映⼈⼯智能在实际使⽤中具体的运⾏环境、⽬标需求等，具体涉及应⽤⽬的、⾏业领域、使⽤环境、服务对象及可能涉及的社会、经济、安全影响等要素。2.智能化⽔平智能化⽔平反映⼈⼯智能系统处理复杂任务、满⾜应⽤需求、独⽴⾃主运⾏等⽅⾯的能⼒。低智能化⽔平下，系统能⼒较低，仅可作为辅助建议，决策需要⼈⼯介⼊。随着智能化⽔平提⾼，⼈⼯介⼊频次和范围不断减⼩。⾼智能化⽔平下，⽆需⼈⼯进⾏⼲预，系统全流程⾃主决策运⾏。3.应⽤规模应⽤规模反映⼈⼯智能系统或服务的覆盖范围及影响⼴度。⽤⼾范围有限或应⽤领域单⼀的系统，如企业内部智能⼯具、区域性服务等，其⻛险影响相对可控。⽤⼾数量达到⼀定规模，或深度嵌⼊关键⾏业领域的业务流程，如智能辅助驾驶、城市运⾏管理、⼯业⽣产调度、⾏业级⾦融⻛控模型等，其安全⻛险可能快速扩散并引发系统性影响。⼆、⻛险级别1.低安全⻛险具有轻微威胁性且影响范围很⼩，对国家安全、社会稳定和公⺠权益的安全基本⽆影响，潜在危害轻微。2.⼀般安全⻛险具有⼀定威胁性但影响范围有限，对国家安全、社会稳定和公⺠权益的安全影响较⼩，潜在危害可控。3.较⼤安全⻛险具有明显威胁性和局部性影响特征，对国家安全、社会稳定和公⺠权益可能带来较⼤影响，产⽣局部社会⾯危害。4.重⼤安全⻛险具有重⼤威胁性和区域性影响特征，对国家安全、社会稳定和公⺠权益可能带来严重影响，产⽣重⼤社会⾯危害。5.特别重⼤安全⻛险具有灾难性和系统性威胁特征，对国家安全、社会秩序和公⺠权益造成颠覆性或不可逆转的特别严重的影响。三、⻛险定级推动⼈⼯智能应⽤安全分类分级国家标准制定⼯作。⾏业领域主管（监管）部⻔参照国家标准制定⾏业标准规范、实施细则，并推动本⾏业领域⼈⼯智能安全应⽤相关分类分级⼯作。1.分类分级国家标准通过⼈⼯智能应⽤安全⻛险分类分级标准，明确分类分级基本流程，以及应⽤场景、智能化⽔平、应⽤规模等分级要素，并给出⾏业领域细化⾏业指南的步骤⽅法，为⾏业领域开展⻛险分类分级提供参考。2.分类分级⾏业细则⾏业领域主管（监管）部⻔结合⾏业领域、使⽤环境、服务对象及可能涉及的社会、经济、安全影响等，制定本⾏业本领域⼈⼯智能安全分类分级标准规范：（1）选取适⽤于本⾏业、本领域的⼈⼯智能安全⻛险分级要素项⽬，并根据⾏业特点进⾏实例化。（2）制定本⾏业、本领域安全⻛险分级细则（定级原则、要素权重），确定⼈⼯智能安全⻛险级别。3.⻛险分类分级⾏业领域主管（监管）部⻔，根据本⾏业、本领域的⼈⼯智能安全⻛险分类分级标准规范，组织本⾏业、本领域⼈⼯智能有关单位开展分类分级⼯作，指导有关单位准确识别、及时防范化解重⼤安全⻛险和较⼤安全⻛险。附件2可信人工智能基本准则落实《全球⼈⼯智能治理倡议》，遵循“以⼈为本、智能向善”的发展⽅向，共同防范应对⼈⼯智能技术失控⻛险，促进⼈⼯智能技术在世界范围内可信应⽤，提出可信⼈⼯智能基本准则如下：1.⼈类最终控制在⼈⼯智能系统关键环节设置⼈类控制机制，使最终裁决权归属⼈类，通过设计安全控制阈值、设置安全终⽌开关、预留⼈⼯⼲预有效窗⼝等措施，确保⼈⼯智能系统能够实现⼈类预期⽬标、不会脱离⼈类监督运⾏失控。2.尊重国家主权研发设计⼈⼯智能产品和提供⼈⼯智能服务时，应尊重所在国主权，严格遵守产品和服务运营所在地的法律，并依法接受监管，不得借助⼈⼯智能产品或服务⼲涉他国内政、社会制度及社会秩序。3.价值观对⻬将和平、发展、公平、正义、⺠主、⾃由的全⼈类共同价值深度融⼊⼈⼯智能系统全⽣命周期。4.提升系统透明度推动⼈⼯智能系统在功能⽬标、运⾏逻辑、模型使⽤、数据来源、决策依据等关键环节的必要披露，增强社会公众信任基础。5.促进可客观验证研究构建客观、公正、透明的测试与认证机制，推动⼈⼯智能系统的功能、性能、安全特性、决策链条等⽅⾯可被技术验证。6.全护在⼈⼯智能系统设计和部署过程中，强化⻛险建模、安全测试和防护机制建设，进⾏全⽣命周期审计与记录，防⽌系统因模型缺陷、外部攻击和技术滥⽤等问题偏离预期⽬标。7.前预应对通过前瞻性⻛险识别评估，积极预防和动态监测，加强应急响应，避免⼈⼯智能失控事件发⽣和扩⼤。8.全球协同共治⽀持联合国发挥主渠道作⽤，推动多边和多⽅跨领域协同共治，促进各国政府、企业、学术机构与社会公众形成合⼒，以多层级、多领域的治理机制推动⼈⼯智能健康发展。附件3术语本框架提到的相关专业术语解释如下。1.⼈⼯智能伦理：开展⼈⼯智能技术基础研究和应⽤实践时遵循的道德规范或准则。2.可解释性：⼈⼯智能系统以⼈类可理解的⽅式呈现其输出结果与输⼊特征之间因果或统计关系的属性。该属性使得⼈类能够追溯并理解影响系统决策的关键因素。3.合成数据：通过算法⽣成或扩展⽽⾮实际收集的数据。4.数据标注：通过⼈⼯操作或使⽤⾃动化技术机制，基于对提⽰信息的响应信息内容，将特定信息如标签、类别或属性添加到⽂本、图⽚、⾳频、视频或者其他数据样本的过程。5.预训练：通过⼤规模数据训练迭代模型参数，使⼈⼯智能模型获得通⽤知识的过程。6.优化训练：在预训练模型基础上，使⽤特定领域数据训练，实现模型参数⼩范围调整，使⼈⼯智能模型强化在特定领域的数据分析处理能⼒的过程。7.对⻬：使⼈⼯智能系统的输出或⾏为与设计者的安全⽬标相符的算法及技术。8.强化学习：⼈⼯智能模型在运⾏环境中采取⾏动、接收运⾏环境反馈的奖励或惩罚反馈，逐步优化形成最优策略以最⼤化累积回报的⼀种学习范式。9.推理：⼈⼯智能模型基于其训练获得的知识和模式识别能⼒，对输⼊信息进⾏分析、处理和逻辑演绎，产⽣合理输出的过程。10.显式标识：在⽣成合成内容或者交互场景界⾯中添加的，以⽂字、声⾳、图形等⽅式呈现并可以被⽤⼾明显感知到的标识。11.隐式标识：采取技术措施在⽣成合成内容⽂件数据中添加的，不易被⽤⼾明显感知到的标识。12.数据投毒：攻击者篡改、注⼊错误、误导数据，“污染”模型的概率分布，进⽽造成准确性、可信度下降的⾏为。13.对抗攻击：通过构造微扰数据等输⼊样本，使⼈⼯智能模型产⽣错误输出或⾏为的攻击⽅式。14.智能体：能够⾃主感知环境、制定决策、采取⾏动实现特定⽬标的智能系统，⼀般具有记忆、规划、使⽤⼯具等基本能⼒。15.安全护栏：针对⼤模型的安全控制措施，通过结合规则库、负⾯判别模型等技术⼿段，对⼤模型输⼊输出内容、数据泄露、提⽰词攻击等进⾏识别、拦截及处置，实现对⼤模型输⼊的验证和过滤，以及限制⼤模型输出不符合预期的内容，保障⽣成内容的可控性、合规性和安全性。